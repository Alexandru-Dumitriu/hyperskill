{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 53\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(user_data)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m     52\u001B[0m     inputs_step \u001B[38;5;241m=\u001B[39m user_data\u001B[38;5;241m.\u001B[39mloc[i:i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m9\u001B[39m, input_cols]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 53\u001B[0m     inputs_action \u001B[38;5;241m=\u001B[39m \u001B[43muser_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction_cols\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     54\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m user_data\u001B[38;5;241m.\u001B[39mloc[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m10\u001B[39m:i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m14\u001B[39m, output_cols]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     55\u001B[0m     train_sequences\u001B[38;5;241m.\u001B[39mappend((inputs_step, inputs_action, outputs))\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1065\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[0;32m   1066\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_value(\u001B[38;5;241m*\u001B[39mkey, takeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_takeable)\n\u001B[1;32m-> 1067\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1069\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n\u001B[0;32m   1070\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multi_take_opportunity(tup):\n\u001B[0;32m   1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multi_take(tup)\n\u001B[1;32m-> 1256\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple_same_dim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001B[0m, in \u001B[0;36m_LocationIndexer._getitem_tuple_same_dim\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_null_slice(key):\n\u001B[0;32m    922\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m--> 924\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mretval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001B[39;00m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001B[39;00m\n\u001B[0;32m    927\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m retval\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1298\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1299\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1240\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1238\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[0;32m   1239\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_listlike_indexer(key, axis)\n\u001B[1;32m-> 1240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reindex_with_indexers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1241\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m   1242\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5355\u001B[0m, in \u001B[0;36mNDFrame._reindex_with_indexers\u001B[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001B[0m\n\u001B[0;32m   5352\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m ensure_platform_int(indexer)\n\u001B[0;32m   5354\u001B[0m \u001B[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001B[39;00m\n\u001B[1;32m-> 5355\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[43mnew_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreindex_indexer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5358\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_dups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5361\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5363\u001B[0m \u001B[38;5;66;03m# If we've made a copy once, no need to make another one\u001B[39;00m\n\u001B[0;32m   5364\u001B[0m copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:743\u001B[0m, in \u001B[0;36mBaseBlockManager.reindex_indexer\u001B[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001B[0m\n\u001B[0;32m    740\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequested axis not found in manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 743\u001B[0m     new_blocks, new_refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_slice_take_blocks_ax0\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_slice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_slice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_na_proxy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_na_proxy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    748\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    749\u001B[0m     parent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mall_none(\u001B[38;5;241m*\u001B[39mnew_refs) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m    750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:912\u001B[0m, in \u001B[0;36mBaseBlockManager._slice_take_blocks_ax0\u001B[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001B[0m\n\u001B[0;32m    910\u001B[0m         refs\u001B[38;5;241m.\u001B[39mappend(weakref\u001B[38;5;241m.\u001B[39mref(blk))\n\u001B[0;32m    911\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 912\u001B[0m     nb \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtaker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_mgr_locs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmgr_locs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    913\u001B[0m     blocks\u001B[38;5;241m.\u001B[39mappend(nb)\n\u001B[0;32m    914\u001B[0m     refs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:880\u001B[0m, in \u001B[0;36mBlock.take_nd\u001B[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001B[0m\n\u001B[0;32m    877\u001B[0m     allow_fill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001B[39;00m\n\u001B[1;32m--> 880\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43malgos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_fill\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;66;03m# Called from three places in managers, all of which satisfy\u001B[39;00m\n\u001B[0;32m    885\u001B[0m \u001B[38;5;66;03m#  this assertion\u001B[39;00m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m new_mgr_locs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001B[0m, in \u001B[0;36mtake_nd\u001B[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mtake(indexer, fill_value\u001B[38;5;241m=\u001B[39mfill_value, allow_fill\u001B[38;5;241m=\u001B[39mallow_fill)\n\u001B[0;32m    116\u001B[0m arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(arr)\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_take_nd_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:163\u001B[0m, in \u001B[0;36m_take_nd_ndarray\u001B[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001B[0m\n\u001B[0;32m    158\u001B[0m     out \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(out_shape, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    160\u001B[0m func \u001B[38;5;241m=\u001B[39m _get_take_nd_function(\n\u001B[0;32m    161\u001B[0m     arr\u001B[38;5;241m.\u001B[39mndim, arr\u001B[38;5;241m.\u001B[39mdtype, out\u001B[38;5;241m.\u001B[39mdtype, axis\u001B[38;5;241m=\u001B[39maxis, mask_info\u001B[38;5;241m=\u001B[39mmask_info\n\u001B[0;32m    162\u001B[0m )\n\u001B[1;32m--> 163\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m flip_order:\n\u001B[0;32m    166\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mT\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:342\u001B[0m, in \u001B[0;36m_get_take_nd_function.<locals>.func\u001B[1;34m(arr, indexer, out, fill_value)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc\u001B[39m(arr, indexer, out, fill_value\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnan):\n\u001B[0;32m    341\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m ensure_platform_int(indexer)\n\u001B[1;32m--> 342\u001B[0m     \u001B[43m_take_nd_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask_info\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hyperskill\\venv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:518\u001B[0m, in \u001B[0;36m_take_nd_object\u001B[1;34m(arr, indexer, out, axis, fill_value, mask_info)\u001B[0m\n\u001B[0;32m    516\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(out\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mshape[axis] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 518\u001B[0m     \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m needs_masking:\n\u001B[0;32m    520\u001B[0m     outindexer \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mslice\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m)] \u001B[38;5;241m*\u001B[39m arr\u001B[38;5;241m.\u001B[39mndim\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape, Embedding, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Input, Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('internship_assignment.csv')\n",
    "selected_cols = ['user_id_hashed', 'dt', 'selected_track_id', 'selected_project_id', 'step_id', 'action']\n",
    "data = data.loc[:, selected_cols]\n",
    "\n",
    "#get the number of ids\n",
    "num_unique_ids = data['step_id'].nunique()\n",
    "\n",
    "# get the unique ids and sort them\n",
    "ids_step = sorted(data['step_id'].unique())\n",
    "\n",
    "# create a dictionary to map the ids to the range 0 to len(ids)-1\n",
    "id_step_map = {id_val: idx for idx, id_val in enumerate(ids_step)}\n",
    "\n",
    "# create a new column 'id_mapped' using the map() method\n",
    "data['step_id'] = data['step_id'].map(id_step_map)\n",
    "\n",
    "# Encode the 'action' column using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['action'] = label_encoder.fit_transform(data['action'])\n",
    "\n",
    "# One-hot encode the 'action' column using pd.get_dummies()\n",
    "data = pd.get_dummies(data, columns=['action'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Get a list of action columns\n",
    "action_cols = [col for col in train_data.columns if col.startswith('action_')]\n",
    "\n",
    "# Create input/output sequences for training data\n",
    "train_sequences = []\n",
    "for user_id, user_data in train_data.groupby('user_id_hashed'):\n",
    "    # Extract the columns that will be used as inputs and output\n",
    "    user_data = user_data.reset_index(drop=True)\n",
    "    input_cols = user_data.drop(['user_id_hashed', 'dt', 'selected_track_id', 'selected_project_id'] + action_cols, axis=1).columns\n",
    "    output_cols = user_data[action_cols].columns\n",
    "\n",
    "    # Separate the data on batches of 10 for the input and 5 for the output\n",
    "    for i in range(0, len(user_data)-20, 10):\n",
    "        inputs_step = user_data.loc[i:i+9, input_cols].values.astype('float32')\n",
    "        inputs_action = user_data.loc[i:i+9, action_cols].values.astype('float32')\n",
    "        outputs = user_data.loc[i+10:i+14, output_cols].values.astype('float32')\n",
    "        train_sequences.append((inputs_step, inputs_action, outputs))\n",
    "\n",
    "# Train the model\n",
    "if len(train_sequences) > 0:\n",
    "    X_train = np.array([i[0] for i in train_sequences])\n",
    "    X_action_train = np.array([i[1] for i in train_sequences])\n",
    "    y_train = np.array([i[2] for i in train_sequences])\n",
    "\n",
    "    # Create GRU model\n",
    "    input_step = Input(shape=(10,))\n",
    "    step_embedding = Embedding(input_dim=num_unique_ids, output_dim=128, input_length=train_sequences[0][0].shape[0])(input_step)\n",
    "    input_action = Input(shape=(10,31))\n",
    "    action_dense = Dense(64, activation='relu')(input_action)\n",
    "    concatenated = Concatenate()([step_embedding, action_dense])\n",
    "    gru_layer = GRU(64)(concatenated)\n",
    "    output_layer = Dense(5*test_data[action_cols].shape[1], activation='softmax')(gru_layer)\n",
    "    reshaped_output = Reshape((5, 31))(output_layer)\n",
    "\n",
    "    model = Model(inputs=[input_step, input_action], outputs=reshaped_output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, X_action_train], y_train, epochs=15, shuffle=False)\n",
    "else:\n",
    "    print(\"No training data\")\n",
    "\n",
    "# Create input/output sequences for testing data\n",
    "test_sequences = []\n",
    "for user_id, user_data in test_data.groupby('user_id_hashed'):\n",
    "    # Extract the columns that will be used as inputs and output\n",
    "    user_data = user_data.reset_index(drop=True)\n",
    "    input_cols = user_data.drop(['user_id_hashed', 'dt', 'selected_track_id', 'selected_project_id'] + action_cols, axis=1).columns\n",
    "    output_cols = user_data[action_cols].columns\n",
    "\n",
    "    # Separate the data on batches of 10 for the input and 5 for the output\n",
    "    for i in range(0, len(user_data)-20, 10):\n",
    "        inputs_step = user_data.loc[i:i+9, input_cols].values.astype('float32')\n",
    "        inputs_action = user_data.loc[i:i+9, action_cols].values.astype('float32')\n",
    "        outputs = user_data.loc[i+10:i+14, output_cols].values.astype('float32')\n",
    "        test_sequences.append((inputs_step, inputs_action, outputs))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "if len(test_sequences) == 0:\n",
    "    print(\"Error: no test data found\")\n",
    "else:\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    num_samples = 0\n",
    "    for inputs_step, inputs_action, outputs in test_sequences:\n",
    "        loss, accuracy = model.evaluate([inputs_step[np.newaxis, :], inputs_action[np.newaxis, :]], outputs[np.newaxis, :])\n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "        num_samples += 1\n",
    "    average_loss = total_loss / num_samples\n",
    "    average_accuracy = total_accuracy / num_samples\n",
    "    print(f'Average loss: {average_loss:.4f}, Average accuracy: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 630ms/step\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create input sequences for all users\n",
    "all_sequences = []\n",
    "for user_id, user_data in data.groupby('user_id_hashed'):\n",
    "    inputs = user_data.drop(['user_id_hashed','selected_project_id','selected_track_id', 'dt'] + action_cols, axis=1).values.astype('float32')[-10:]\n",
    "    inputs_action = user_data[action_cols].values.astype('float32')[-10:]\n",
    "    all_sequences.append((inputs, inputs_action))\n",
    "\n",
    "input_step = np.array([i[0] for i in all_sequences])\n",
    "input_action = np.array([i[1] for i in all_sequences])\n",
    "\n",
    "# Make predictions using the trained model\n",
    "all_predictions = model.predict([input_step, input_action])\n",
    "\n",
    "# Decode the predicted actions using label encoding\n",
    "decoded_predictions = list()\n",
    "for i in range(0, data['user_id_hashed'].nunique()):\n",
    "    decoded_predictions.append(label_encoder.inverse_transform(np.argmax(all_predictions[i], axis=1)))\n",
    "\n",
    "# Extract the 5 next predicted actions for each user\n",
    "next_actions = {}\n",
    "for i, user_id in enumerate(data['user_id_hashed'].unique()):\n",
    "    user_predictions = decoded_predictions[i]\n",
    "    next_actions[user_id] = user_predictions\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "    # Create a CSV writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    csvwriter.writerow(['user_id_hashed', 'actions'])\n",
    "\n",
    "    # Write the predicted next actions for each user to the CSV file\n",
    "    for user_id, user_next_actions in next_actions.items():\n",
    "        user_next_actions_str = ' '.join(user_next_actions)\n",
    "        csvwriter.writerow([user_id, user_next_actions_str])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
